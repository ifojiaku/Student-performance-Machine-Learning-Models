{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Libraries and Warning Suppression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, cross_validate, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import make_scorer, precision_score, recall_score, f1_score\n",
    "from sklearn.metrics import roc_auc_score, classification_report, accuracy_score, confusion_matrix\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function for score aggregation\n",
    "def aggregate_classes(score):\n",
    "    if score < 55:\n",
    "        return \"Below 55\"\n",
    "    elif score <= 60:\n",
    "        return \"55-60\"\n",
    "    elif score <= 65:\n",
    "        return \"61-65\"\n",
    "    elif score <= 70:\n",
    "        return \"66-70\"\n",
    "    elif score <= 75:\n",
    "        return \"71-75\"\n",
    "    elif score <= 80:\n",
    "        return \"76-80\"\n",
    "    else:\n",
    "        return \"81+\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Dataset and Preprocess data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and preprocess data\n",
    "df = pd.read_csv(\"student_performance/StudentPerformanceFactorsAdjusted.csv\")\n",
    "\n",
    "# Encode categorical variables\n",
    "label_encoders = {}\n",
    "categorical_columns = df.select_dtypes(include='object').columns\n",
    "\n",
    "for col in categorical_columns:\n",
    "    le = LabelEncoder()\n",
    "    df[col] = le.fit_transform(df[col])\n",
    "    label_encoders[col] = le\n",
    "\n",
    "# Prepare features and target\n",
    "X = df.drop('Exam_Score', axis=1)\n",
    "y = df['Exam_Score'].map(aggregate_classes)\n",
    "\n",
    "# Scale features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "X_scaled = pd.DataFrame(X_scaled, columns=X.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Untuned without SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define scorers\n",
    "scorers = {\n",
    "    'accuracy': 'accuracy',\n",
    "    'precision': make_scorer(precision_score, average='weighted', zero_division=0),\n",
    "    'recall': make_scorer(recall_score, average='weighted', zero_division=0),\n",
    "    'f1': make_scorer(f1_score, average='weighted', zero_division=0),\n",
    "    'roc_auc': make_scorer(roc_auc_score, average='macro', multi_class='ovr')\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating initial model (before tuning, before SMOTE)...\n"
     ]
    }
   ],
   "source": [
    "# Initial model evaluation (before tuning, before SMOTE)\n",
    "print(\"\\nEvaluating initial model (before tuning, before SMOTE)...\")\n",
    "initial_mlp = MLPClassifier(random_state=42, max_iter=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Metrics before tuning (original data):\n",
      "Accuracy: Mean = 0.8842, Std = 0.0058\n",
      "Precision: Mean = 0.8844, Std = 0.0081\n",
      "Recall: Mean = 0.8842, Std = 0.0058\n",
      "F1: Mean = 0.8839, Std = 0.0069\n",
      "AUC: Mean = nan, Std = nan\n"
     ]
    }
   ],
   "source": [
    "# Tuning\n",
    "cv_results = cross_validate(initial_mlp, X_scaled, y, cv=5, scoring=scorers)\n",
    "\n",
    "# Calculate metrics before tuning\n",
    "metrics_before_tuning = {\n",
    "    \"Accuracy\": (cv_results['test_accuracy'].mean(), cv_results['test_accuracy'].std()),\n",
    "    \"Precision\": (cv_results['test_precision'].mean(), cv_results['test_precision'].std()),\n",
    "    \"Recall\": (cv_results['test_recall'].mean(), cv_results['test_recall'].std()),\n",
    "    \"F1\": (cv_results['test_f1'].mean(), cv_results['test_f1'].std()),\n",
    "    \"AUC\": (cv_results['test_roc_auc'].mean(), cv_results['test_roc_auc'].std())\n",
    "}\n",
    "\n",
    "print(\"\\nMetrics before tuning (original data):\")\n",
    "for metric, (mean, std) in metrics_before_tuning.items():\n",
    "    print(f\"{metric}: Mean = {mean:.4f}, Std = {std:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tuned without SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define parameter grid for MLP\n",
    "param_grid = {\n",
    "    'hidden_layer_sizes': [(50,), (100,), (50, 50), (100, 50)],\n",
    "    'activation': ['relu', 'tanh'],\n",
    "    'learning_rate_init': [0.001, 0.01],\n",
    "    'max_iter': [500]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Performing hyperparameter tuning on original data...\n"
     ]
    }
   ],
   "source": [
    "# Perform GridSearchCV on original data\n",
    "print(\"\\nPerforming hyperparameter tuning on original data...\")\n",
    "grid_search = GridSearchCV(MLPClassifier(random_state=42), param_grid, cv=5, scoring='f1_weighted', n_jobs=-1)\n",
    "grid_search.fit(X_scaled, y)\n",
    "best_mlp = grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Metrics after tuning (original data):\n",
      "Accuracy: Mean = 0.8931, Std = 0.0075\n",
      "Precision: Mean = 0.8889, Std = 0.0083\n",
      "Recall: Mean = 0.8931, Std = 0.0075\n",
      "F1: Mean = 0.8906, Std = 0.0079\n",
      "AUC: Mean = nan, Std = nan\n"
     ]
    }
   ],
   "source": [
    "# Evaluate tuned model on original data\n",
    "cv_results_tuned = cross_validate(best_mlp, X_scaled, y, cv=5, scoring=scorers)\n",
    "\n",
    "# Calculate metrics after tuning\n",
    "metrics_after_tuning = {\n",
    "    \"Accuracy\": (cv_results_tuned['test_accuracy'].mean(), cv_results_tuned['test_accuracy'].std()),\n",
    "    \"Precision\": (cv_results_tuned['test_precision'].mean(), cv_results_tuned['test_precision'].std()),\n",
    "    \"Recall\": (cv_results_tuned['test_recall'].mean(), cv_results_tuned['test_recall'].std()),\n",
    "    \"F1\": (cv_results_tuned['test_f1'].mean(), cv_results_tuned['test_f1'].std()),\n",
    "    \"AUC\": (cv_results_tuned['test_roc_auc'].mean(), cv_results_tuned['test_roc_auc'].std())\n",
    "}\n",
    "\n",
    "print(\"\\nMetrics after tuning (original data):\")\n",
    "for metric, (mean, std) in metrics_after_tuning.items():\n",
    "    print(f\"{metric}: Mean = {mean:.4f}, Std = {std:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Untuned with SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Applying SMOTE...\n"
     ]
    }
   ],
   "source": [
    "# Apply SMOTE\n",
    "print(\"\\nApplying SMOTE...\")\n",
    "smote = SMOTE(random_state=42)\n",
    "X_balanced, y_balanced = smote.fit_resample(X_scaled, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating initial model on SMOTE data...\n"
     ]
    }
   ],
   "source": [
    "# Evaluate initial model on SMOTE data\n",
    "print(\"\\nEvaluating initial model on SMOTE data...\")\n",
    "cv_results_smote = cross_validate(initial_mlp, X_balanced, y_balanced, cv=5, scoring=scorers)\n",
    "\n",
    "metrics_before_smote = {\n",
    "    \"Accuracy\": (cv_results_smote['test_accuracy'].mean(), cv_results_smote['test_accuracy'].std()),\n",
    "    \"Precision\": (cv_results_smote['test_precision'].mean(), cv_results_smote['test_precision'].std()),\n",
    "    \"Recall\": (cv_results_smote['test_recall'].mean(), cv_results_smote['test_recall'].std()),\n",
    "    \"F1\": (cv_results_smote['test_f1'].mean(), cv_results_smote['test_f1'].std()),\n",
    "    \"AUC\": (cv_results_smote['test_roc_auc'].mean(), cv_results_smote['test_roc_auc'].std())\n",
    "}\n",
    "\n",
    "print(\"\\nMetrics before tuning (SMOTE data):\")\n",
    "for metric, (mean, std) in metrics_before_smote.items():\n",
    "    print(f\"{metric}: Mean = {mean:.4f}, Std = {std:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tuned with SMOTE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Performing final hyperparameter tuning on SMOTE data...\n"
     ]
    }
   ],
   "source": [
    "# Final model tuning on SMOTE data\n",
    "print(\"\\nPerforming final hyperparameter tuning on SMOTE data...\")\n",
    "grid_search_final = GridSearchCV(MLPClassifier(random_state=42), param_grid, cv=5, scoring='f1_weighted', n_jobs=-1)\n",
    "grid_search_final.fit(X_balanced, y_balanced)\n",
    "best_mlp_final = grid_search_final.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Final metrics (tuned model on SMOTE data):\n",
      "Accuracy: Mean = 0.9703, Std = 0.0080\n",
      "Precision: Mean = 0.9709, Std = 0.0077\n",
      "Recall: Mean = 0.9703, Std = 0.0080\n",
      "F1: Mean = 0.9702, Std = 0.0079\n",
      "AUC: Mean = nan, Std = nan\n"
     ]
    }
   ],
   "source": [
    "# Final evaluation\n",
    "cv_results_final = cross_validate(best_mlp_final, X_balanced, y_balanced, cv=5, scoring=scorers)\n",
    "\n",
    "metrics_after_smote = {\n",
    "    \"Accuracy\": (cv_results_final['test_accuracy'].mean(), cv_results_final['test_accuracy'].std()),\n",
    "    \"Precision\": (cv_results_final['test_precision'].mean(), cv_results_final['test_precision'].std()),\n",
    "    \"Recall\": (cv_results_final['test_recall'].mean(), cv_results_final['test_recall'].std()),\n",
    "    \"F1\": (cv_results_final['test_f1'].mean(), cv_results_final['test_f1'].std()),\n",
    "    \"AUC\": (cv_results_final['test_roc_auc'].mean(), cv_results_final['test_roc_auc'].std())\n",
    "}\n",
    "\n",
    "print(\"\\nFinal metrics (tuned model on SMOTE data):\")\n",
    "for metric, (mean, std) in metrics_after_smote.items():\n",
    "    print(f\"{metric}: Mean = {mean:.4f}, Std = {std:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final Evaluations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best parameters: {'activation': 'relu', 'hidden_layer_sizes': (100,), 'learning_rate_init': 0.01, 'max_iter': 500}\n",
      "\n",
      "Final Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       55-60       1.00      1.00      1.00       656\n",
      "       61-65       0.96      0.95      0.95       733\n",
      "       66-70       0.92      0.92      0.92       635\n",
      "       71-75       0.98      0.96      0.97       664\n",
      "       76-80       1.00      1.00      1.00       715\n",
      "         81+       0.97      1.00      0.99       669\n",
      "\n",
      "    accuracy                           0.97      4072\n",
      "   macro avg       0.97      0.97      0.97      4072\n",
      "weighted avg       0.97      0.97      0.97      4072\n",
      "\n",
      "Final Test Set Accuracy: 0.9718\n"
     ]
    }
   ],
   "source": [
    "# Split data for final predictions\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_balanced, y_balanced, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train final model and make predictions\n",
    "best_mlp_final.fit(X_train, y_train)\n",
    "y_pred = best_mlp_final.predict(X_test)\n",
    "\n",
    "print(\"\\nBest parameters:\", grid_search_final.best_params_)\n",
    "print(\"\\nFinal Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(f\"Final Test Set Accuracy: {accuracy_score(y_test, y_pred):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization functions\n",
    "def plot_class_distribution():\n",
    "    plt.figure(figsize=(15, 5))\n",
    "    \n",
    "    plt.subplot(1, 2, 1)\n",
    "    original_distribution = pd.Series(y).value_counts()\n",
    "    plt.bar(original_distribution.index, original_distribution.values)\n",
    "    plt.title('Class Distribution Before SMOTE')\n",
    "    plt.xlabel('Score Range')\n",
    "    plt.ylabel('Number of Samples')\n",
    "    \n",
    "    plt.subplot(1, 2, 2)\n",
    "    balanced_distribution = pd.Series(y_balanced).value_counts()\n",
    "    plt.bar(balanced_distribution.index, balanced_distribution.values)\n",
    "    plt.title('Class Distribution After SMOTE')\n",
    "    plt.xlabel('Score Range')\n",
    "    plt.ylabel('Number of Samples')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_metrics_comparison():\n",
    "    metrics = {\n",
    "        \"Accuracy\": [metrics_before_tuning[\"Accuracy\"][0], \n",
    "                    metrics_after_tuning[\"Accuracy\"][0],\n",
    "                    metrics_before_smote[\"Accuracy\"][0], \n",
    "                    metrics_after_smote[\"Accuracy\"][0]],\n",
    "        \"Precision\": [metrics_before_tuning[\"Precision\"][0],\n",
    "                     metrics_after_tuning[\"Precision\"][0],\n",
    "                     metrics_before_smote[\"Precision\"][0],\n",
    "                     metrics_after_smote[\"Precision\"][0]],\n",
    "        \"Recall\": [metrics_before_tuning[\"Recall\"][0],\n",
    "                  metrics_after_tuning[\"Recall\"][0],\n",
    "                  metrics_before_smote[\"Recall\"][0],\n",
    "                  metrics_after_smote[\"Recall\"][0]],\n",
    "        \"F1 Score\": [metrics_before_tuning[\"F1\"][0],\n",
    "                    metrics_after_tuning[\"F1\"][0],\n",
    "                    metrics_before_smote[\"F1\"][0],\n",
    "                    metrics_after_smote[\"F1\"][0]],\n",
    "        \"AUC\": [metrics_before_tuning[\"AUC\"][0],\n",
    "                metrics_after_tuning[\"AUC\"][0],\n",
    "                metrics_before_smote[\"AUC\"][0],\n",
    "                metrics_after_smote[\"AUC\"][0]]\n",
    "    }\n",
    "    \n",
    "    metrics_df = pd.DataFrame(metrics, \n",
    "                            index=[\"Before Tuning\", \"After Tuning\",\n",
    "                                  \"SMOTE Before Tuning\", \"SMOTE After Tuning\"])\n",
    "    metrics_df.plot(kind='bar', figsize=(12, 6), colormap=\"viridis\")\n",
    "    plt.title(\"Performance Metrics Comparison\")\n",
    "    plt.ylabel(\"Score\")\n",
    "    plt.legend(title=\"Metrics\", bbox_to_anchor=(1.05, 1))\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix():\n",
    "    # Split data for final evaluation\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_balanced, y_balanced, test_size=0.2, random_state=42)\n",
    "    best_mlp_final.fit(X_train, y_train)\n",
    "    y_pred = best_mlp_final.predict(X_test)\n",
    "    \n",
    "    plt.figure(figsize=(10, 8))\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
    "                xticklabels=sorted(y.unique()),\n",
    "                yticklabels=sorted(y.unique()))\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('True')\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'y' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[19], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Generate plots\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[43mplot_class_distribution\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m plot_metrics_comparison()\n\u001b[0;32m      4\u001b[0m plot_confusion_matrix()\n",
      "Cell \u001b[1;32mIn[16], line 6\u001b[0m, in \u001b[0;36mplot_class_distribution\u001b[1;34m()\u001b[0m\n\u001b[0;32m      3\u001b[0m plt\u001b[38;5;241m.\u001b[39mfigure(figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m15\u001b[39m, \u001b[38;5;241m5\u001b[39m))\n\u001b[0;32m      5\u001b[0m plt\u001b[38;5;241m.\u001b[39msubplot(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m----> 6\u001b[0m original_distribution \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mSeries(\u001b[43my\u001b[49m)\u001b[38;5;241m.\u001b[39mvalue_counts()\n\u001b[0;32m      7\u001b[0m plt\u001b[38;5;241m.\u001b[39mbar(original_distribution\u001b[38;5;241m.\u001b[39mindex, original_distribution\u001b[38;5;241m.\u001b[39mvalues)\n\u001b[0;32m      8\u001b[0m plt\u001b[38;5;241m.\u001b[39mtitle(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mClass Distribution Before SMOTE\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'y' is not defined"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Generate plots\n",
    "plot_class_distribution()\n",
    "plot_metrics_comparison()\n",
    "plot_confusion_matrix()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
